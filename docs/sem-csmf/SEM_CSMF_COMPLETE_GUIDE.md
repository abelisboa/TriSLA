# SEM-CSMF Module Complete Guide

**Version:** 3.5.0  
**Date:** 2025-01-27  
**Module:** Semantic-Enhanced Communication Service Management Function

---

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Module Architecture](#module-architecture)
3. [Processing Pipeline](#processing-pipeline)
4. [OWL Ontology](#owl-ontology)
5. [NLP (Natural Language Processing)](#nlp-natural-language-processing)
6. [NEST Generation](#nest-generation)
7. [Interfaces](#interfaces)
8. [Persistence](#persistence)
9. [Usage Examples](#usage-examples)
10. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ Overview

The **SEM-CSMF (Semantic-Enhanced Communication Service Management Function)** is the module responsible for receiving high-level intents, validating them semantically using an OWL ontology, processing them with NLP, and generating NESTs (Network Slice Templates) for network slice provisioning.

### Objectives

1. **Semantic Interpretation:** Validate intents against an OWL ontology  
2. **NLP Processing:** Extract structured information from natural language  
3. **NEST Generation:** Convert intents into Network Slice Templates  
4. **Integration:** Communicate with the Decision Engine and ML-NSMF  

### Key Features

- **OWL Ontology:** Complete ontology in Turtle format (`.ttl`)  
- **NLP:** Natural language processing using spaCy  
- **Reasoning:** Semantic reasoning engine using Pellet  
- **Persistence:** PostgreSQL for intents and NESTs  
- **Observability:** OpenTelemetry for traces and metrics  

---

## ğŸ—ï¸ Module Architecture

### Directory Structure

apps/sem-csmf/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ main.py # FastAPI application
â”‚ â”œâ”€â”€ intent_processor.py # Intent processing
â”‚ â”œâ”€â”€ nest_generator.py # NEST generation
â”‚ â”œâ”€â”€ nest_generator_db.py # NEST generation with persistence
â”‚ â”œâ”€â”€ ontology/ # OWL ontology
â”‚ â”‚ â”œâ”€â”€ trisla.ttl # Main ontology
â”‚ â”‚ â”œâ”€â”€ loader.py # Ontology loader
â”‚ â”‚ â”œâ”€â”€ reasoner.py # Reasoning engine
â”‚ â”‚ â”œâ”€â”€ parser.py # Intent parser
â”‚ â”‚ â””â”€â”€ matcher.py # Semantic matcher
â”‚ â”œâ”€â”€ nlp/ # Natural language processing
â”‚ â”‚ â””â”€â”€ parser.py # NLP parser
â”‚ â”œâ”€â”€ grpc_server.py # gRPC server (I-01)
â”‚ â”œâ”€â”€ grpc_client.py # gRPC client
â”‚ â”œâ”€â”€ grpc_client_retry.py # gRPC client with retry
â”‚ â”œâ”€â”€ kafka_producer.py # Kafka producer (I-02)
â”‚ â”œâ”€â”€ kafka_producer_retry.py # Kafka producer with retry
â”‚ â”œâ”€â”€ database.py # Database configuration
â”‚ â”œâ”€â”€ repository.py # Data repository
â”‚ â”œâ”€â”€ models/ # Pydantic models
â”‚ â”‚ â”œâ”€â”€ intent.py
â”‚ â”‚ â””â”€â”€ nest.py
â”‚ â””â”€â”€ models/ # SQLAlchemy models
â”‚ â””â”€â”€ db_models.py
â”œâ”€â”€ tests/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


### Main Components

1. **IntentProcessor** â€” Core intent processing component  
2. **OntologyLoader** â€” OWL ontology loader  
3. **SemanticReasoner** â€” Semantic reasoning engine  
4. **NLPParser** â€” Natural language parser  
5. **NESTGenerator** â€” NEST generator  
6. **DecisionEngineClient** â€” gRPC client for the Decision Engine  

---

## âš™ï¸ Processing Pipeline

### End-to-End Flow

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Intent Receivedâ”‚ (HTTP REST or gRPC)
â”‚ (Natural â”‚
â”‚ Language or â”‚
â”‚ Structured) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NLP Parser â”‚ (Extracts slice type and requirements)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ontology â”‚ (Semantic validation)
â”‚ Parser â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Semantic â”‚ (Semantic matching)
â”‚ Matcher â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NEST Generator â”‚ (Generates Network Slice Template)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”œâ”€â”€â”€â–º I-01 (gRPC) â”€â”€â–º Decision Engine
â”‚
â””â”€â”€â”€â–º I-02 (Kafka) â”€â”€â–º ML-NSMF


### Detailed Steps

1. **Intent Reception**
   - HTTP REST: `POST /api/v1/intents`
   - gRPC: `ProcessIntent`

2. **NLP Processing** (for natural language)
   - Slice type extraction  
   - SLA requirement extraction  
   - Data normalization  

3. **Semantic Validation**
   - OWL ontology loading  
   - Validation against classes and properties  
   - Semantic reasoning  

4. **NEST Generation**
   - GST-to-NEST conversion  
   - Requirement validation  
   - Persistence in PostgreSQL  

5. **Downstream Dispatch**
   - I-01 (gRPC): Metadata for the Decision Engine  
   - I-02 (Kafka): Complete NEST for ML-NSMF  

---

## ğŸ“œ OWL Ontology

### Overview

The OWL ontology is located at `apps/sem-csmf/src/ontology/trisla.ttl` and is dynamically loaded by the module.

**Full Documentation:** [`ontology/ONTOLOGY_IMPLEMENTATION_GUIDE.md`](ontology/ONTOLOGY_IMPLEMENTATION_GUIDE.md)

### Usage in SEM-CSMF

```python
from ontology.loader import OntologyLoader
from ontology.reasoner import SemanticReasoner

# Load ontology
loader = OntologyLoader()
loader.load(apply_reasoning=True)

# Create reasoner
reasoner = SemanticReasoner(loader)
reasoner.initialize()

# Validate requirements
sla_dict = {"latency": "10ms", "throughput": "100Mbps"}
is_valid = reasoner.validate_sla_requirements("URLLC", sla_dict)


Main Classes

Intent â€” Service intent

SliceType â€” Slice type (eMBB, URLLC, mMTC)

SLA â€” Service Level Agreement

SLO â€” Service Level Objective

Metric â€” Performance metrics

ğŸ’¬ NLP (Natural Language Processing)
Overview

NLP is used to process natural language intents and extract structured information.

File: apps/sem-csmf/src/nlp/parser.py

Capabilities

Slice Type Extraction

Identifies eMBB, URLLC, mMTC

Uses heuristics and spaCy

SLA Requirement Extraction

Latency

Throughput

Reliability

Jitter

Packet loss

Usage Example

from nlp.parser import NLPParser

parser = NLPParser()

text = "I need a URLLC slice with maximum latency of 10ms"
result = parser.parse_intent_text(text)

# Result:
# {
#   "slice_type": "URLLC",
#   "requirements": {"latency": "10ms"}
# }

ğŸ—ï¸ NEST Generation
Overview

The NEST (Network Slice Template) is generated from a semantically validated intent.

File: apps/sem-csmf/src/nest_generator.py

Process

GST â†’ NEST Conversion

GST (Generic Slice Template) is converted into NEST

Ontology-based validation

Persistence

Stored in PostgreSQL

Metadata recorded

Dispatch

gRPC to Decision Engine (I-01)

Kafka to ML-NSMF (I-02)

Example NEST

{
  "nest_id": "nest-urllc-001",
  "intent_id": "intent-001",
  "slice_type": "URLLC",
  "sla_requirements": {
    "latency": "10ms",
    "throughput": "100Mbps",
    "reliability": 0.99999
  },
  "domains": ["RAN", "Transport", "Core"],
  "created_at": "2025-01-27T10:00:00Z"
}

ğŸ”Œ Interfaces
Interface I-01 (gRPC)

Type: gRPC
Direction: SEM-CSMF â†’ Decision Engine
Endpoint: decision-engine:50051

Payload:

message NESTMetadata {
  string nest_id = 1;
  string intent_id = 2;
  string tenant_id = 3;
  string service_type = 4;
  map<string, string> sla_requirements = 5;
}

Example:

from grpc_client import DecisionEngineClient

client = DecisionEngineClient()
await client.send_nest_metadata(
    intent_id="intent-001",
    nest_id="nest-urllc-001",
    tenant_id="tenant-001",
    service_type="URLLC",
    sla_requirements={"latency": "10ms"}
)

Interface I-02 (Kafka)

Type: Kafka
Direction: SEM-CSMF â†’ ML-NSMF
Topic: sem-csmf-nests

Payload:

Interface I-02 (Kafka)

Type: Kafka
Direction: SEM-CSMF â†’ ML-NSMF
Topic: sem-csmf-nests

Payload:

{
  "nest_id": "nest-urllc-001",
  "intent_id": "intent-001",
  "slice_type": "URLLC",
  "sla_requirements": {...},
  "timestamp": "2025-01-27T10:00:00Z"
}

ğŸ’¾ Persistence
PostgreSQL

Configuration:

DATABASE_URL=postgresql://user:pass@localhost/trisla


Models:

IntentModel â€” Stored intents

NESTModel â€” Generated NESTs

Repository Example:

from repository import IntentRepository

repo = IntentRepository()
intent = await repo.create_intent(intent_data)

ğŸ’¡ Usage Examples
Example 1: Process Structured Intent
from intent_processor import IntentProcessor
from models.intent import Intent, SliceType, SLARequirements

processor = IntentProcessor()

intent = Intent(
    intent_id="intent-001",
    tenant_id="tenant-001",
    service_type=SliceType.URLLC,
    sla_requirements=SLARequirements(
        latency="10ms",
        throughput="100Mbps",
        reliability=0.99999
    )
)

validated = await processor.validate_semantic(intent)
nest = await processor.generate_nest(validated)

Example 2: Process Natural Language Intent
intent = Intent(
    intent_id="intent-002",
    sla_requirements=SLARequirements()
)

validated = await processor.validate_semantic(
    intent,
    intent_text="I need a URLLC slice with maximum latency of 10ms"
)

ğŸ”§ Troubleshooting
Problem 1: Ontology does not load

Symptom: ImportError: owlready2 is not installed

Solution:

pip install owlready2==0.40

Problem 2: NLP does not work

Symptom: OSError: SpaCy model not found

Solution:

python -m spacy download en_core_web_sm

Problem 3: gRPC connection failure

Symptom: grpc._channel._InactiveRpcError

Solution:

Verify that the Decision Engine is running

Check endpoint DECISION_ENGINE_GRPC

Verify network connectivity

Problem 4: Kafka message not sent

Symptom: kafka.errors.KafkaError

Solution:

Verify that Kafka is running

Check KAFKA_BOOTSTRAP_SERVERS

Verify that the topic exists

ğŸ“Š Observability
Prometheus Metrics
Metric	Type	Description
sem_csmf_intents_total	Counter	Total processed intents
sem_csmf_processing_duration_seconds	Histogram	Processing time
sem_csmf_ontology_validations_total	Counter	Total ontology validations
sem_csmf_nests_generated_total	Counter	Total generated NESTs
OTLP Traces

Spans:

process_intent â€” Full intent processing

validate_semantic â€” Semantic validation

generate_nest â€” NEST generation

send_i01 â€” I-01 dispatch (gRPC)

send_i02 â€” I-02 dispatch (Kafka)

ğŸ“š References

Ontology: ontology/ONTOLOGY_IMPLEMENTATION_GUIDE.md

ML-NSMF: ../ml-nsmf/ML_NSMF_COMPLETE_GUIDE.md

Decision Engine: See Decision Engine documentation

Module README: ../../apps/sem-csmf/README.md

ğŸ¯ Conclusion

The SEM-CSMF provides intelligent semantic interpretation of intents using OWL ontology and NLP. The module:

âœ… Processes intents with semantic validation

âœ… Uses OWL ontology for reasoning

âœ… Processes natural language with NLP

âœ… Generates NESTs for provisioning

âœ… Integrates with the Decision Engine and ML-NSMF

âœ… Is observable via Prometheus and OpenTelemetry

For more information, refer to:

apps/sem-csmf/src/intent_processor.py â€” Core processor

apps/sem-csmf/src/ontology/ â€” OWL ontology

apps/sem-csmf/src/nlp/parser.py â€” NLP parser

End of Guide
