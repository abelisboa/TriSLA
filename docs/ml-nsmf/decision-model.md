# Modelo de Decis√£o ‚Äî ML-NSMF

**Vers√£o:** S4.0  
**Data:** 2025-01-27  
**Origem do Conte√∫do:** `ML_NSMF_COMPLETE_GUIDE.md` (se√ß√µes Treinamento do Modelo, Funcionamento do M√≥dulo)

---

## üìã Sum√°rio

1. [Vis√£o Geral](#vis√£o-geral)
2. [Modelo ML](#modelo-ml)
3. [Features](#features)
4. [Feature Engineering](#feature-engineering)
5. [Treinamento](#treinamento)
6. [Avalia√ß√£o](#avalia√ß√£o)
7. [Interpreta√ß√£o de Predi√ß√µes](#interpreta√ß√£o-de-predi√ß√µes)

---

## Vis√£o Geral

O modelo de decis√£o do ML-NSMF utiliza Machine Learning (Random Forest Regressor) para prever a viabilidade de aceita√ß√£o de SLAs. O modelo recebe features extra√≠das do NEST e m√©tricas atuais da infraestrutura, e retorna um score de viabilidade (0.0 a 1.0).

### Objetivo

Prever se um SLA pode ser atendido com base em:
- Requisitos de SLA do NEST (lat√™ncia, throughput, confiabilidade, etc.)
- Estado atual da infraestrutura (CPU, mem√≥ria, bandwidth, slices ativos)
- Hist√≥rico de viola√ß√µes (quando dispon√≠vel)

### Score de Viabilidade

- **0.0 - 0.4**: Baixo risco ‚Üí **ACCEPT**
- **0.4 - 0.7**: Risco m√©dio ‚Üí **CONDITIONAL_ACCEPT** ou **RENEGOTIATE**
- **0.7 - 1.0**: Alto risco ‚Üí **REJECT**

---

## Modelo ML

### Tipo de Modelo

**Algoritmo:** Random Forest Regressor

**Par√¢metros:**
- `n_estimators`: 100
- `max_depth`: 10
- `min_samples_split`: 5
- `min_samples_leaf`: 2
- `random_state`: 42
- `n_jobs`: -1 (paraleliza√ß√£o)

### Arquivos do Modelo

- **Modelo treinado:** `apps/ml-nsmf/models/viability_model.pkl`
- **Scaler:** `apps/ml-nsmf/models/scaler.pkl`
- **Metadados:** `apps/ml-nsmf/models/model_metadata.json`

### Carregamento

```python
import pickle
import json

# Carregar modelo
with open("models/viability_model.pkl", "rb") as f:
    model = pickle.load(f)

# Carregar scaler
with open("models/scaler.pkl", "rb") as f:
    scaler = pickle.load(f)

# Carregar metadados
with open("models/model_metadata.json", "r") as f:
    metadata = json.load(f)
```

---

## Features

### Features do Dataset (13 features)

| Feature | Tipo | Descri√ß√£o | Fonte |
|---------|------|-----------|-------|
| `latency` | float | Lat√™ncia requerida (ms) | NEST |
| `throughput` | float | Throughput requerido (Mbps) | NEST |
| `reliability` | float | Confiabilidade requerida (0-1) | NEST |
| `jitter` | float | Jitter requerido (ms) | NEST |
| `packet_loss` | float | Taxa de perda de pacotes (0-1) | NEST |
| `cpu_utilization` | float | Utiliza√ß√£o de CPU (0-1) | M√©tricas NASP |
| `memory_utilization` | float | Utiliza√ß√£o de mem√≥ria (0-1) | M√©tricas NASP |
| `network_bandwidth_available` | float | Bandwidth dispon√≠vel (Mbps) | M√©tricas NASP |
| `active_slices_count` | int | N√∫mero de slices ativos | M√©tricas NASP |
| `slice_type_encoded` | int | Tipo de slice (1=eMBB, 2=URLLC, 3=mMTC) | NEST |
| `latency_throughput_ratio` | float | Ratio lat√™ncia/throughput | Feature engineering |
| `reliability_packet_loss_ratio` | float | Ratio confiabilidade/perda | Feature engineering |
| `jitter_latency_ratio` | float | Ratio jitter/lat√™ncia | Feature engineering |

### Target

**Vari√°vel alvo:** `viability_score` (0.0 a 1.0)

- **0.0**: SLA totalmente vi√°vel
- **1.0**: SLA totalmente invi√°vel

---

## Feature Engineering

### Features Derivadas

O modelo utiliza feature engineering para criar features derivadas que capturam rela√ß√µes entre requisitos e m√©tricas:

```python
# Features derivadas
features['latency_throughput_ratio'] = features['latency'] / (features['throughput'] + 0.001)
features['reliability_packet_loss_ratio'] = features['reliability'] / (features['packet_loss'] + 0.001)
features['jitter_latency_ratio'] = features['jitter'] / (features['latency'] + 0.001)
```

### Normaliza√ß√£o

Todas as features s√£o normalizadas usando **StandardScaler** antes da predi√ß√£o:

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

### Extra√ß√£o de Features do NEST

```python
def extract_features_from_nest(nest: Dict, metrics: Dict) -> np.ndarray:
    """Extrai features do NEST e m√©tricas"""
    features = np.array([
        nest['sla_requirements']['latency'],
        nest['sla_requirements']['throughput'],
        nest['sla_requirements']['reliability'],
        nest['sla_requirements']['jitter'],
        nest['sla_requirements']['packet_loss'],
        metrics['cpu_utilization'],
        metrics['memory_utilization'],
        metrics['network_bandwidth_available'],
        metrics['active_slices_count'],
        encode_slice_type(nest['slice_type']),
        nest['sla_requirements']['latency'] / (nest['sla_requirements']['throughput'] + 0.001),
        nest['sla_requirements']['reliability'] / (nest['sla_requirements']['packet_loss'] + 0.001),
        nest['sla_requirements']['jitter'] / (nest['sla_requirements']['latency'] + 0.001)
    ])
    return features
```

---

## Treinamento

### Dataset de Treinamento

**Arquivo:** `apps/ml-nsmf/data/datasets/trisla_ml_dataset.csv`

**Estrutura:**
- 13 features (colunas de entrada)
- 1 target (`viability_score`)
- Formato CSV

### Script de Treinamento

**Arquivo:** `apps/ml-nsmf/training/train_model.py`

**Processo:**
1. Carregar dataset
2. Feature engineering
3. Separar features e target
4. Split train/test (80/20)
5. Normaliza√ß√£o (StandardScaler)
6. Treinar modelo (Random Forest)
7. Avaliar modelo
8. Cross-validation (5-fold)
9. Salvar modelo, scaler e metadados

**Executar:**
```bash
cd apps/ml-nsmf
python training/train_model.py
```

### Par√¢metros de Treinamento

- **Test size:** 0.2 (20% para teste)
- **Random state:** 42 (reprodutibilidade)
- **Cross-validation:** 5-fold
- **Scoring:** R¬≤ score

---

## Avalia√ß√£o

### M√©tricas de Avalia√ß√£o

**Objetivos:**
- **R¬≤ Score:** > 0.85
- **MAE (Mean Absolute Error):** < 0.05
- **MSE (Mean Squared Error):** < 0.01
- **Cross-Validation:** CV score > 0.85

**Exemplo de sa√≠da:**
```
Modelo treinado e salvo com sucesso!
Test R¬≤: 0.9028
Test MAE: 0.0464
```

### Feature Importance

O modelo calcula import√¢ncia de features automaticamente. Exemplo:

```json
{
  "reliability": 0.370,
  "latency_throughput_ratio": 0.254,
  "latency": 0.130,
  "throughput": 0.089,
  "cpu_utilization": 0.052,
  "memory_utilization": 0.038,
  "packet_loss": 0.025,
  "jitter": 0.020,
  "network_bandwidth_available": 0.015,
  "active_slices_count": 0.004,
  "slice_type_encoded": 0.002,
  "reliability_packet_loss_ratio": 0.001,
  "jitter_latency_ratio": 0.000
}
```

### Retreinamento

**Quando retreinar:**
1. Novos dados dispon√≠veis (acumular novos exemplos)
2. Degrada√ß√£o de performance (R¬≤ < 0.80)
3. Mudan√ßas no ambiente (novos tipos de slice, mudan√ßas na infraestrutura)
4. Per√≠odo regular (mensal ou trimestral)

**Processo:**
1. Coletar novos dados do NASP
2. Adicionar ao dataset existente
3. Executar script de treinamento
4. Validar novo modelo
5. Se melhor, substituir modelo antigo
6. Se pior, manter modelo atual

---

## Interpreta√ß√£o de Predi√ß√µes

### Score de Viabilidade

O modelo retorna um score de viabilidade (0.0 a 1.0):

- **0.0 - 0.4**: Baixo risco
  - SLA provavelmente ser√° atendido
  - Recomenda√ß√£o: **ACCEPT**

- **0.4 - 0.7**: Risco m√©dio
  - SLA pode ser atendido com condi√ß√µes
  - Recomenda√ß√£o: **CONDITIONAL_ACCEPT** ou **RENEGOTIATE**

- **0.7 - 1.0**: Alto risco
  - SLA provavelmente n√£o ser√° atendido
  - Recomenda√ß√£o: **REJECT**

### Exemplo de Predi√ß√£o

```python
from predictor import RiskPredictor

predictor = RiskPredictor()

# Predi√ß√£o
prediction = await predictor.predict(normalized_features)

# Resultado
{
    "viability_score": 0.75,
    "risk_level": "high",
    "confidence": 0.85,
    "recommendation": "REJECT",
    "timestamp": "2025-01-27T10:00:00Z"
}
```

### Confian√ßa da Predi√ß√£o

A confian√ßa √© calculada com base na vari√¢ncia das predi√ß√µes das √°rvores do Random Forest:

- **Alta confian√ßa (> 0.8)**: Predi√ß√£o confi√°vel
- **M√©dia confian√ßa (0.5-0.8)**: Predi√ß√£o moderadamente confi√°vel
- **Baixa confian√ßa (< 0.5)**: Predi√ß√£o pouco confi√°vel (considerar retreinar modelo)

---

## Origem do Conte√∫do

Este documento foi consolidado a partir de:
- `ML_NSMF_COMPLETE_GUIDE.md` ‚Äî Se√ß√µes "Treinamento do Modelo", "Funcionamento do M√≥dulo"
- `ML_NSMF_COMPLETE_GUIDE.md` ‚Äî Se√ß√£o "Predi√ß√£o e XAI" (interpreta√ß√£o de predi√ß√µes)

**√öltima atualiza√ß√£o:** 2025-01-27  
**Vers√£o:** S4.0

