# Implementa√ß√£o ‚Äî ML-NSMF

**Vers√£o:** S4.0  
**Data:** 2025-01-27  
**Origem do Conte√∫do:** `ML_NSMF_COMPLETE_GUIDE.md` (se√ß√µes Arquitetura, Integra√ß√£o, Interface I-03, Observabilidade, Troubleshooting)

---

## üìã Sum√°rio

1. [Arquitetura do M√≥dulo](#arquitetura-do-m√≥dulo)
2. [Componentes Principais](#componentes-principais)
3. [Interfaces de Comunica√ß√£o](#interfaces-de-comunica√ß√£o)
4. [Configura√ß√£o](#configura√ß√£o)
5. [Exemplos de Implementa√ß√£o](#exemplos-de-implementa√ß√£o)
6. [Troubleshooting](#troubleshooting)

---

## Arquitetura do M√≥dulo

### Estrutura de Diret√≥rios

```
apps/ml-nsmf/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                 # Aplica√ß√£o FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ predictor.py            # Classe RiskPredictor (predi√ß√£o)
‚îÇ   ‚îú‚îÄ‚îÄ kafka_consumer.py       # Consumer Kafka (recebe NESTs)
‚îÇ   ‚îú‚îÄ‚îÄ kafka_producer.py       # Producer Kafka (envia predi√ß√µes)
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ viability_model.pkl    # Modelo treinado (Random Forest)
‚îÇ   ‚îú‚îÄ‚îÄ scaler.pkl              # Scaler para normaliza√ß√£o
‚îÇ   ‚îî‚îÄ‚îÄ model_metadata.json     # Metadados do modelo
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trisla_ml_dataset.csv  # Dataset de treinamento
‚îÇ   ‚îî‚îÄ‚îÄ training/               # Scripts de treinamento
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ unit/                   # Testes unit√°rios
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

### Tecnologias Utilizadas

- **Framework**: FastAPI (Python 3.10+)
- **ML**: scikit-learn (Random Forest)
- **XAI**: SHAP, LIME
- **Comunica√ß√£o**: Kafka (kafka-python)
- **Observabilidade**: OpenTelemetry

---

## Componentes Principais

### 1. RiskPredictor

**Arquivo:** `src/predictor.py`

**Responsabilidades:**
- Carregar modelo treinado
- Normalizar features
- Gerar predi√ß√µes
- Gerar explica√ß√µes XAI

**M√©todos principais:**
```python
class RiskPredictor:
    def __init__(self):
        """Inicializa predictor e carrega modelo"""
        
    async def predict(self, features: np.ndarray) -> Dict:
        """Gera predi√ß√£o de viabilidade"""
        
    async def explain(self, prediction: Dict, features: np.ndarray) -> Dict:
        """Gera explica√ß√£o XAI"""
        
    async def predict_from_nest(self, nest: Dict, metrics: Dict) -> Dict:
        """Predi√ß√£o completa a partir de NEST e m√©tricas"""
```

### 2. NESTConsumer

**Arquivo:** `src/kafka_consumer.py`

**Responsabilidades:**
- Consumir NESTs do SEM-NSMF (I-02)
- Processar mensagens ass√≠ncronas
- Disparar predi√ß√µes

**M√©todos principais:**
```python
class NESTConsumer:
    def __init__(self):
        """Inicializa consumer Kafka"""
        
    async def consume_nests(self):
        """Consome NESTs do t√≥pico sem-csmf-nests"""
        
    async def process_nest(self, nest: Dict):
        """Processa NEST e dispara predi√ß√£o"""
```

### 3. MetricsCollector

**Arquivo:** `src/metrics_collector.py`

**Responsabilidades:**
- Coletar m√©tricas atuais via NASP Adapter
- Agregar m√©tricas de RAN, Transport, Core
- Cache de m√©tricas

**M√©todos principais:**
```python
class MetricsCollector:
    async def collect_metrics(self) -> Dict:
        """Coleta m√©tricas atuais"""
        
    async def get_domain_metrics(self, domain: str) -> Dict:
        """Obt√©m m√©tricas de um dom√≠nio espec√≠fico"""
```

### 4. FeatureExtractor

**Arquivo:** `src/feature_extractor.py`

**Responsabilidades:**
- Extrair features do NEST
- Extrair features das m√©tricas
- Feature engineering (ratios, combina√ß√µes)

**M√©todos principais:**
```python
class FeatureExtractor:
    def extract_from_nest(self, nest: Dict) -> np.ndarray:
        """Extrai features do NEST"""
        
    def extract_from_metrics(self, metrics: Dict) -> np.ndarray:
        """Extrai features das m√©tricas"""
        
    def engineer_features(self, features: np.ndarray) -> np.ndarray:
        """Feature engineering"""
```

### 5. XAIExplainer

**Arquivo:** `src/xai_explainer.py`

**Responsabilidades:**
- Gerar explica√ß√µes SHAP
- Gerar explica√ß√µes LIME (fallback)
- Gerar explica√ß√µes fallback (feature importance)

**M√©todos principais:**
```python
class XAIExplainer:
    async def explain_shap(self, model, features: np.ndarray) -> Dict:
        """Gera explica√ß√£o SHAP"""
        
    async def explain_lime(self, model, features: np.ndarray) -> Dict:
        """Gera explica√ß√£o LIME"""
        
    async def explain_fallback(self, model) -> Dict:
        """Gera explica√ß√£o fallback"""
```

### 6. PredictionProducer

**Arquivo:** `src/kafka_producer.py`

**Responsabilidades:**
- Enviar predi√ß√µes ao Decision Engine (I-03)
- Serializa√ß√£o JSON
- Retry autom√°tico

**M√©todos principais:**
```python
class PredictionProducer:
    async def send_prediction(self, prediction: Dict) -> bool:
        """Envia predi√ß√£o ao Decision Engine"""
```

---

## Interfaces de Comunica√ß√£o

### Interface I-02 (Kafka) ‚Äî Entrada

**Protocolo:** Kafka  
**Dire√ß√£o:** SEM-NSMF ‚Üí ML-NSMF  
**T√≥pico:** `sem-csmf-nests`  
**Parti√ß√µes:** 3  
**Replica√ß√£o:** 1

**Implementa√ß√£o:**
```python
from kafka import KafkaConsumer
import json

consumer = KafkaConsumer(
    'sem-csmf-nests',
    bootstrap_servers=['kafka:9092'],
    value_deserializer=lambda m: json.loads(m.decode('utf-8'))
)

for message in consumer:
    nest = message.value
    # Processar NEST
    prediction = await predictor.predict_from_nest(nest, metrics)
```

### Interface I-03 (Kafka) ‚Äî Sa√≠da

**Protocolo:** Kafka  
**Dire√ß√£o:** ML-NSMF ‚Üí Decision Engine  
**T√≥pico:** `ml-nsmf-predictions`  
**Parti√ß√µes:** 3  
**Replica√ß√£o:** 1

**Schema da Mensagem:**
```json
{
  "prediction_id": "pred-001",
  "nest_id": "nest-urllc-001",
  "intent_id": "intent-001",
  "viability_score": 0.75,
  "risk_level": "high",
  "confidence": 0.85,
  "recommendation": "REJECT",
  "xai_explanation": {
    "method": "SHAP",
    "features_importance": {...},
    "reasoning": "..."
  },
  "timestamp": "2025-01-27T10:00:00Z"
}
```

**Implementa√ß√£o:**
```python
from kafka import KafkaProducer
import json

producer = KafkaProducer(
    bootstrap_servers=['kafka:9092'],
    value_serializer=lambda v: json.dumps(v).encode('utf-8')
)

producer.send('ml-nsmf-predictions', value=prediction_data)
```

### NASP Adapter (HTTP REST)

**Protocolo:** HTTP REST  
**Dire√ß√£o:** ML-NSMF ‚Üí NASP Adapter  
**Endpoint:** `http://nasp-adapter:8080/api/v1/metrics`

**Implementa√ß√£o:**
```python
import httpx

async with httpx.AsyncClient() as client:
    response = await client.get("http://nasp-adapter:8080/api/v1/metrics")
    metrics = response.json()
```

---

## Configura√ß√£o

### Vari√°veis de Ambiente

```bash
# Kafka
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_TOPIC_NEST=sem-csmf-nests
KAFKA_TOPIC_PREDICTION=ml-nsmf-predictions
KAFKA_RETRY_ATTEMPTS=3

# Modelo
MODEL_PATH=models/viability_model.pkl
SCALER_PATH=models/scaler.pkl
MODEL_METADATA_PATH=models/model_metadata.json

# XAI
XAI_ENABLED=true
XAI_METHOD=SHAP  # SHAP, LIME, ou AUTO
XAI_TIMEOUT=500  # ms

# NASP Adapter
NASP_ADAPTER_URL=http://nasp-adapter:8080
NASP_ADAPTER_TIMEOUT=5.0

# OpenTelemetry
OTLP_ENDPOINT=http://otlp-collector:4317
OTLP_PROTOCOL=grpc
```

### Depend√™ncias

**requirements.txt:**
```
fastapi==0.104.1
uvicorn==0.24.0
scikit-learn==1.3.2
numpy==1.24.3
pandas==2.1.1
shap==0.43.0
lime==0.2.0.1
kafka-python==2.0.2
httpx==0.25.0
opentelemetry-api==1.21.0
opentelemetry-sdk==1.21.0
opentelemetry-instrumentation-fastapi==0.42b0
pydantic==2.5.0
```

---

## Exemplos de Implementa√ß√£o

### Exemplo 1: Predi√ß√£o Completa

```python
from predictor import RiskPredictor
from feature_extractor import FeatureExtractor
from metrics_collector import MetricsCollector

predictor = RiskPredictor()
extractor = FeatureExtractor()
collector = MetricsCollector()

# Coletar m√©tricas
metrics = await collector.collect_metrics()

# Extrair features
nest_features = extractor.extract_from_nest(nest)
metrics_features = extractor.extract_from_metrics(metrics)
features = np.concatenate([nest_features, metrics_features])

# Predi√ß√£o
prediction = await predictor.predict(features)

# Explica√ß√£o XAI
explanation = await predictor.explain(prediction, features)
```

### Exemplo 2: Consumer Kafka

```python
from kafka_consumer import NESTConsumer
from predictor import RiskPredictor

consumer = NESTConsumer()
predictor = RiskPredictor()

async def process_nest(nest: Dict):
    # Predi√ß√£o
    prediction = await predictor.predict_from_nest(nest, metrics)
    
    # Enviar ao Decision Engine
    await producer.send_prediction(prediction)

# Consumir NESTs
async for nest in consumer.consume_nests():
    await process_nest(nest)
```

### Exemplo 3: API REST Endpoint

```python
from fastapi import FastAPI
from predictor import RiskPredictor

app = FastAPI()
predictor = RiskPredictor()

@app.post("/api/v1/predict")
async def predict_viability(nest: Dict, metrics: Dict):
    prediction = await predictor.predict_from_nest(nest, metrics)
    return prediction
```

---

## Troubleshooting

### Problema 1: Modelo n√£o carrega

**Sintoma:** `FileNotFoundError: models/viability_model.pkl`

**Solu√ß√£o:**
- Verificar se modelo existe: `ls models/viability_model.pkl`
- Treinar modelo: `python training/train_model.py`
- Verificar `MODEL_PATH` nas vari√°veis de ambiente

### Problema 2: SHAP n√£o funciona

**Sintoma:** `ImportError: shap is not installed`

**Solu√ß√£o:**
```bash
pip install shap==0.43.0
```

### Problema 3: Kafka n√£o recebe mensagens

**Sintoma:** Consumer n√£o recebe NESTs

**Solu√ß√£o:**
- Verificar se Kafka est√° rodando
- Verificar `KAFKA_BOOTSTRAP_SERVERS`
- Verificar t√≥pico existe: `kafka-topics --list`
- Verificar consumer group: `kafka-consumer-groups --describe`

### Problema 4: M√©tricas n√£o coletadas

**Sintoma:** `httpx.ConnectError` ao consultar NASP Adapter

**Solu√ß√£o:**
- Verificar se NASP Adapter est√° rodando
- Verificar `NASP_ADAPTER_URL`
- Verificar conectividade de rede
- Verificar timeout: `NASP_ADAPTER_TIMEOUT`

### Problema 5: Predi√ß√£o muito lenta

**Sintoma:** Predi√ß√£o demora > 1 segundo

**Solu√ß√£o:**
- Desabilitar XAI temporariamente: `XAI_ENABLED=false`
- Usar LIME em vez de SHAP: `XAI_METHOD=LIME`
- Verificar recursos computacionais (CPU, mem√≥ria)
- Otimizar feature extraction

---

## Observabilidade

### M√©tricas Prometheus

O m√≥dulo exp√µe m√©tricas via endpoint `/metrics`:

| M√©trica | Tipo | Descri√ß√£o |
|---------|------|-----------|
| `trisla_predictions_total` | Counter | Total de predi√ß√µes realizadas |
| `trisla_prediction_duration_seconds` | Histogram | Dura√ß√£o de predi√ß√£o |
| `trisla_prediction_accuracy` | Gauge | Acur√°cia do modelo (quando dispon√≠vel) |
| `trisla_xai_explanations_total` | Counter | Total de explica√ß√µes XAI geradas |
| `trisla_xai_duration_seconds` | Histogram | Dura√ß√£o de gera√ß√£o de explica√ß√£o |
| `trisla_kafka_messages_received_total` | Counter | Total de mensagens Kafka recebidas (I-02) |
| `trisla_kafka_messages_sent_total` | Counter | Total de mensagens Kafka enviadas (I-03) |

### Traces OpenTelemetry

Traces distribu√≠dos s√£o gerados para rastreabilidade:

- **Span:** `ml_nsmf.receive_nest` ‚Äî Recep√ß√£o de NEST (I-02)
- **Span:** `ml_nsmf.collect_metrics` ‚Äî Coleta de m√©tricas
- **Span:** `ml_nsmf.extract_features` ‚Äî Extra√ß√£o de features
- **Span:** `ml_nsmf.predict_viability` ‚Äî Predi√ß√£o de viabilidade
- **Span:** `ml_nsmf.generate_xai` ‚Äî Gera√ß√£o de explica√ß√£o XAI
- **Span:** `ml_nsmf.send_prediction` ‚Äî Envio de predi√ß√£o (I-03)

### Logs Estruturados

Logs estruturados incluem:
- `prediction_id`: Identificador da predi√ß√£o
- `nest_id`: Refer√™ncia ao NEST
- `viability_score`: Score de viabilidade
- `confidence`: Confian√ßa da predi√ß√£o
- `processing_time`: Tempo de processamento
- `xai_method`: M√©todo XAI usado (SHAP/LIME/fallback)

---

## Origem do Conte√∫do

Este documento foi consolidado a partir de:
- `ML_NSMF_COMPLETE_GUIDE.md` ‚Äî Se√ß√µes "Arquitetura do M√≥dulo", "Integra√ß√£o com Outros M√≥dulos", "Interface I-03", "Observabilidade", "Troubleshooting"

**√öltima atualiza√ß√£o:** 2025-01-27  
**Vers√£o:** S4.0

