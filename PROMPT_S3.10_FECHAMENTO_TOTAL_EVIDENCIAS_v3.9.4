Objetivo: Colocar o TriSLA 100% evidenciável (inclui Besu TX real) e gerar evidências para resultados reais: latência, throughput/volumes Kafka, métricas de recursos, ML-metrics, XAI (RENEG/REJECT/ACCEPT) e governança on-chain.

Regras:

Não alterar thresholds/regras do Decision Engine

Não alterar modelo ML

Permitido: corrigir infra e instrumentação (DNS Prometheus, tópicos Kafka, build/push Besu, coleta de métricas, logs estruturados)

ACCEPT deve vir por SLA permissivo + métricas completas, não por “ajeitar regra”.

FASE 0 — CHECKPOINT (obrigatório)
ssh node006
cd /home/porvir5g/gtp5g/trisla
set -euo pipefail

NS=trisla
REG=ghcr.io/abelisboa
VER=v3.9.4
TS=$(date +%Y%m%d_%H%M%S)
WORKDIR=/home/porvir5g/gtp5g/trisla/run_s3_10_full_${VER}_${TS}
mkdir -p "$WORKDIR"

kubectl get pods -n $NS -o wide | tee "$WORKDIR/pods_before.txt"
kubectl get deploy -n $NS | tee "$WORKDIR/deploy_before.txt"
kubectl get svc -n $NS | tee "$WORKDIR/svc_before.txt"

GATE 0

Deve existir pelo menos 1 pod Running para:

portal-backend

sem-csmf

decision-engine

ml-nsmf

kafka

Se não: ABORTAR e estabilizar cluster.

FASE 1 — BESU: BUILD + PUSH não-interativo + DEPLOY
1.1 Build
docker build --no-cache -t $REG/trisla-besu:$VER apps/besu | tee "$WORKDIR/build_besu.log"

1.2 Login GHCR (sem interação “aberta”)
# NÃO use set -x aqui.
read -s -p "GHCR_TOKEN (write:packages): " GHCR_TOKEN; echo
echo "$GHCR_TOKEN" | docker login ghcr.io -u abelisboa --password-stdin
unset GHCR_TOKEN

1.3 Push
docker push $REG/trisla-besu:$VER | tee "$WORKDIR/push_besu.log"

1.4 Helm upgrade Besu

Ajuste o path da chave se seu chart usar outro nome; aqui assumo besu.image.tag.

helm upgrade --install trisla helm/trisla -n $NS \
  --reuse-values \
  --set besu.image.tag=$VER \
  | tee "$WORKDIR/helm_besu_upgrade.log"

kubectl rollout status -n $NS deploy/trisla-besu --timeout=300s | tee "$WORKDIR/rollout_besu.log"
kubectl get pods -n $NS | grep besu | tee "$WORKDIR/besu_pods.txt"

GATE 1 (Besu)
BESU_POD=$(kubectl get pod -n $NS -l app=trisla-besu -o jsonpath='{.items[0].metadata.name}')
kubectl exec -n $NS "$BESU_POD" -- bash -lc 'ss -lntp | grep 8545' | tee "$WORKDIR/besu_8545.txt"


Se não houver listener 8545: ABORTAR.

FASE 2 — KAFKA: tópicos explícitos + prova de eventos
2.1 Descobrir pod Kafka
KAFKA_POD=$(kubectl get pods -n $NS | awk '/kafka/{print $1; exit}')
test -n "$KAFKA_POD" || (echo "ABORT: Kafka pod não encontrado" && exit 1)

2.2 Garantir tópicos obrigatórios (criar se não existir)
kubectl exec -n $NS "$KAFKA_POD" -- bash -lc \
  "/opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list" \
  | tee "$WORKDIR/kafka_topics_before.txt"

ensure_topic () {
  local t="$1"
  if ! grep -qx "$t" "$WORKDIR/kafka_topics_before.txt"; then
    echo "Criando tópico $t..."
    kubectl exec -n $NS "$KAFKA_POD" -- bash -lc \
      "/opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --topic $t --partitions 3 --replication-factor 1"
  fi
}

ensure_topic "trisla-i04-decisions"
ensure_topic "trisla-i05-actions"
ensure_topic "trisla-i05-sla-agents"
ensure_topic "trisla-ml-predictions"
ensure_topic "trisla-ml-xai"
ensure_topic "trisla-decision-events"

kubectl exec -n $NS "$KAFKA_POD" -- bash -lc \
  "/opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list" \
  | tee "$WORKDIR/kafka_topics_after.txt"

GATE 2 (tópicos)

Todos os tópicos acima devem constar em kafka_topics_after.txt. Se faltar algum: ABORTAR.

FASE 3 — AUDIT: sla_compliance (o que ele exige exatamente)

Aqui é onde você para de “tentar SLA no escuro” e passa a operar com engenharia.

3.1 Identificar cálculo e métricas exigidas
kubectl exec -n $NS deploy/trisla-decision-engine -- bash -lc \
  "grep -R \"sla_compliance\" -n /app/src || true" \
  | tee "$WORKDIR/grep_sla_compliance.txt"

kubectl exec -n $NS deploy/trisla-decision-engine -- bash -lc \
  "grep -R \"rule-002\" -n /app/src || true" \
  | tee "$WORKDIR/grep_rule_002.txt"

3.2 Extrair “lista de métricas” que entram no compliance

Procure por nomes como:

latency, jitter, packet_loss, throughput, availability

pesos, thresholds por slice

Se não ficar evidente só com grep:

kubectl exec -n $NS deploy/trisla-decision-engine -- bash -lc \
  "python - <<'PY'
import os, re
paths=[]
for root,_,files in os.walk('/app/src'):
  for f in files:
    if f.endswith('.py'):
      paths.append(os.path.join(root,f))
keys=set()
pat=re.compile(r\"(latency|jitter|packet_loss|throughput|availability|cpu|memory|disk)\", re.I)
for p in paths:
  try:
    txt=open(p,'r',encoding='utf-8',errors='ignore').read()
    if 'sla_compliance' in txt or 'compliance' in txt:
      for m in pat.findall(txt):
        keys.add(m.lower())
  except: pass
print('METRICS_KEYS_FOUND=',sorted(keys))
PY" | tee "$WORKDIR/compliance_metric_keys.txt"

GATE 3

Você precisa ter uma lista explícita de quais métricas são obrigatórias para sla_compliance.

FASE 4 — PROMETHEUS: provar que cada métrica existe e retorna valor
4.1 Validar DNS/URL do Prometheus que ML usa
kubectl -n $NS get deploy trisla-ml-nsmf -o jsonpath='{.spec.template.spec.containers[0].env}' | tee "$WORKDIR/ml_env.json"

4.2 Consultar Prometheus e salvar queries mínimas

Use port-forward do Prometheus real:

# ajuste nome/namespace se necessário (o seu já foi encontrado antes)
kubectl -n monitoring port-forward svc/monitoring-kube-prometheus-prometheus 9090:9090 >"$WORKDIR/pf_prometheus.log" 2>&1 &
PF_PID=$!
sleep 2

curl -fsS "http://127.0.0.1:9090/-/healthy" | tee "$WORKDIR/prometheus_health.txt"


Agora, para cada métrica do compliance, faça ao menos 1 query e salve o JSON bruto:

q() {
  local name="$1"; shift
  local query="$1"
  curl -fsS "http://127.0.0.1:9090/api/v1/query?query=$(python -c "import urllib.parse; print(urllib.parse.quote('''$query'''))")" \
    > "$WORKDIR/prom_${name}.json" || true
}

# Exemplos (ajuste conforme sua lista real do GATE 3):
q "cpu"  'sum(rate(container_cpu_usage_seconds_total{namespace="trisla"}[2m]))'
q "mem"  'sum(container_memory_working_set_bytes{namespace="trisla"})'
q "net"  'sum(rate(container_network_receive_bytes_total{namespace="trisla"}[2m]))'
q "net2" 'sum(rate(container_network_transmit_bytes_total{namespace="trisla"}[2m]))'

kill $PF_PID || true

GATE 4

Cada prom_*.json deve ter status":"success" e pelo menos 1 valor numérico.

Se alguma métrica do compliance não existir no Prometheus, você achou o motivo do RENEG eterno.

FASE 5 — XAI: provar que explica RENEG/REJECT (independente de ACCEPT)
5.1 Teste /predict e /explain (sem depender do Decision Engine)
kubectl -n $NS port-forward svc/trisla-ml-nsmf 8081:8081 >"$WORKDIR/pf_ml.log" 2>&1 &
MLPF=$!
sleep 2

curl -fsS -X POST http://127.0.0.1:8081/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{"slice_type":"eMBB","cpu":2,"memory":2048,"latency":50,"bandwidth":20}' \
  | tee "$WORKDIR/ml_predict.json" >/dev/null

curl -fsS -X POST http://127.0.0.1:8081/api/v1/explain \
  -H "Content-Type: application/json" \
  -d '{"slice_type":"eMBB","cpu":2,"memory":2048,"latency":50,"bandwidth":20}' \
  | tee "$WORKDIR/ml_explain.json" >/dev/null

kill $MLPF || true

GATE 5

ml_predict.json contém timestamp_utc

ml_explain.json contém explanation e explanation_available

FASE 6 — GERAR ACCEPT (sem mudar regra): SLA permissivo + métricas completas

Aqui você vai parar de “chutar valores” e executar um sweep controlado até achar ACCEPT.

6.1 Descobrir NodePort do portal-backend
PORTAL_SVC=trisla-portal-backend
NODEPORT=$(kubectl get svc -n $NS $PORTAL_SVC -o jsonpath='{.spec.ports[0].nodePort}')
NODEIP=$(hostname -I | awk '{print $1}')
BASEURL="http://${NODEIP}:${NODEPORT}"
echo "$BASEURL" | tee "$WORKDIR/portal_url.txt"

curl -fsS "$BASEURL/openapi.json" -o "$WORKDIR/portal_openapi.json"

6.2 Script de sweep (mMTC ultra permissivo)
python3 - <<'PY'
import json, time, requests, itertools, os
BASEURL=os.environ.get("BASEURL")
out=os.environ.get("WORKDIR")
assert BASEURL and out

def submit(devices, latency, throughput, reliability):
    payload={
      "template_id":"template:mMTC",
      "form_values":{
        "service_type":"mMTC",
        "devices":str(devices),
        "latency":str(latency),
        "throughput":str(throughput),
        "reliability":str(reliability)
      }
    }
    r=requests.post(f"{BASEURL}/api/v1/sla/submit", json=payload, timeout=30)
    return r.status_code, r.json()

grid_devices=[1,5,10,50]
grid_latency=[200,500,1000]
grid_thr=[1,2,5]
grid_rel=[90,95,98]

for i,(d,l,t,rp) in enumerate(itertools.product(grid_devices,grid_latency,grid_thr,grid_rel), start=1):
    code, js = submit(d,l,t,rp)
    fn=f"sweep_{i:03d}_d{d}_l{l}_t{t}_r{rp}.json"
    with open(os.path.join(out, fn),"w") as f: json.dump(js,f,indent=2)
    # tente inferir decisão do retorno (ajuste se o campo tiver outro nome)
    decision = js.get("decision") or js.get("action") or js.get("status") or ""
    print(i, code, d,l,t,rp, decision)
    time.sleep(0.2)
PY


Execute com:

export BASEURL
export WORKDIR

GATE 6 (ACCEPT real)

O sweep precisa produzir pelo menos 1 JSON contendo ACCEPT.

Se nenhum ACCEPT aparecer, então:

ou compliance ainda sem métricas necessárias

ou regra 002 exige métricas específicas ainda ausentes

Nesse caso, você volta ao GATE 3/4 e corrige a coleta de métricas — sem tocar regra.

FASE 7 — BLOCKCHAIN: provar TX quando ACCEPT existir

Assim que tiver ACCEPT:

capture decision_id

verifique bc-nssmf

verifique Besu

kubectl logs -n $NS deploy/trisla-bc-nssmf --since=20m | tee "$WORKDIR/bc_nssmf.log"
kubectl logs -n $NS deploy/trisla-besu --since=20m | tee "$WORKDIR/besu.log"

GATE 7

Nos logs do bc-nssmf deve existir:

hash / tx

decision_id / sla_id

timestamp

FASE 8 — KAFKA: provar evento publicado (RENEG/REJECT/ACCEPT)
kubectl exec -n $NS "$KAFKA_POD" -- bash -lc \
  "/opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic trisla-decision-events --from-beginning --timeout-ms 10000 --max-messages 50" \
  | tee "$WORKDIR/kafka_decision_events.txt"

test -s "$WORKDIR/kafka_decision_events.txt" || (echo "ABORT: sem eventos em trisla-decision-events" && exit 1)

FASE 9 — MÉTRICAS DE RECURSOS + DISCO + CHECKSUM
kubectl top pods -n $NS | tee "$WORKDIR/top_pods.txt"
kubectl top nodes | tee "$WORKDIR/top_nodes.txt"
df -h | tee "$WORKDIR/df_host.txt"

find "$WORKDIR" -type f -size 0 -print | tee "$WORKDIR/empty_files.txt" || true
sha256sum $(find "$WORKDIR" -type f | sort) > "$WORKDIR/CHECKSUMS.sha256"

echo "PASS: FULL evidence pack em $WORKDIR"