Objetivo

Instrumentar métricas reais de plano de dados (latency, packet_loss, throughput) usando tráfego real gerado no cluster, integrando-as ao Prometheus para permitir sla_compliance ≥ 0.9, gerando ACCEPT real, com XAI completo, evento Kafka e transação Blockchain, sem alterar regras, ML ou thresholds.

PRÉ-REQUISITOS

Acesso SSH via ssh node006

Namespace: trisla

Prometheus operacional no namespace monitoring

ML-NSMF já apontando corretamente para Prometheus

Kafka, Decision Engine e Portal Backend operacionais

FASE 0 — CHECKPOINT E CONTEXTO
ssh node006
cd /home/porvir5g/gtp5g/trisla
set -euo pipefail

NS=trisla
MON_NS=monitoring
WORKDIR=$(pwd)/run_s3_12_plano_dados_real_$(date +%Y%m%d_%H%M%S)
mkdir -p "$WORKDIR"


Capturar estado inicial:

kubectl get pods -n $NS -o wide > $WORKDIR/pods_before.txt
kubectl get svc -n $NS > $WORKDIR/services_before.txt
kubectl get deploy -n $NS > $WORKDIR/deploys_before.txt

FASE 1 — DEPLOY GERADOR DE TRÁFEGO REAL (IPERF3 SERVER)
1.1 Deployment iperf3-server
cat <<'EOF' | kubectl apply -n $NS -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trisla-iperf3-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: trisla-iperf3-server
  template:
    metadata:
      labels:
        app: trisla-iperf3-server
    spec:
      containers:
      - name: iperf3
        image: networkstatic/iperf3
        args: ["-s"]
        ports:
        - containerPort: 5201
EOF

1.2 Service
kubectl expose deploy trisla-iperf3-server \
  -n $NS \
  --name=trisla-iperf3 \
  --port=5201


Validar:

kubectl rollout status deploy/trisla-iperf3-server -n $NS

FASE 2 — GERADOR DE TRÁFEGO (CLIENTE) + EXPORTAÇÃO DE MÉTRICAS
2.1 Job iperf3-client (tráfego contínuo)
cat <<'EOF' | kubectl apply -n $NS -f -
apiVersion: batch/v1
kind: Job
metadata:
  name: trisla-iperf3-client
spec:
  template:
    spec:
      restartPolicy: OnFailure
      containers:
      - name: iperf3-client
        image: networkstatic/iperf3
        command:
        - /bin/sh
        - -c
        - |
          while true; do
            iperf3 -c trisla-iperf3 -t 10 -J > /tmp/iperf.json
            sleep 2
          done
EOF

FASE 3 — EXPORTER DE MÉTRICAS DE TRÁFEGO (REAL)
3.1 Criar Exporter Python (latency, throughput, packet_loss)
cat <<'EOF' > traffic_exporter.py
from flask import Flask, Response
import json, time, os, subprocess

app = Flask(__name__)

def read_iperf():
    try:
        with open("/tmp/iperf.json") as f:
            data = json.load(f)
        end = data["end"]
        return {
            "throughput": end["sum_received"]["bits_per_second"] / 1e6,
            "packet_loss": end["sum_received"].get("lost_percent", 0.0),
            "latency": end.get("streams", [{}])[0].get("sender", {}).get("mean_rtt", 10)
        }
    except Exception:
        return None

@app.route("/metrics")
def metrics():
    m = read_iperf()
    if not m:
        return Response("", mimetype="text/plain")

    return Response(f"""
trisla_network_throughput_mbps {m['throughput']}
trisla_network_packet_loss_ratio {m['packet_loss']}
trisla_network_latency_ms {m['latency']}
""", mimetype="text/plain")

app.run(host="0.0.0.0", port=9105)
EOF

3.2 Containerizar Exporter
cat <<'EOF' > Dockerfile.traffic
FROM python:3.11-slim
RUN pip install flask
COPY traffic_exporter.py /traffic_exporter.py
CMD ["python", "/traffic_exporter.py"]
EOF

docker build -t ghcr.io/abelisboa/trisla-traffic-exporter:v1 .
docker push ghcr.io/abelisboa/trisla-traffic-exporter:v1

FASE 4 — DEPLOY EXPORTER
cat <<'EOF' | kubectl apply -n $NS -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trisla-traffic-exporter
spec:
  replicas: 1
  selector:
    matchLabels:
      app: trisla-traffic-exporter
  template:
    metadata:
      labels:
        app: trisla-traffic-exporter
    spec:
      containers:
      - name: exporter
        image: ghcr.io/abelisboa/trisla-traffic-exporter:v1
        ports:
        - containerPort: 9105
EOF

kubectl expose deploy trisla-traffic-exporter \
  -n $NS \
  --name=trisla-traffic-exporter \
  --port=9105

FASE 5 — PROMETHEUS (SERVICE MONITOR REAL)
cat <<EOF | kubectl apply -f -
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: trisla-traffic-exporter
  namespace: $MON_NS
spec:
  selector:
    matchLabels:
      app: trisla-traffic-exporter
  namespaceSelector:
    matchNames:
    - trisla
  endpoints:
  - port: http
    path: /metrics
    interval: 5s
EOF


Validar no Prometheus:

kubectl -n $MON_NS port-forward svc/monitoring-kube-prometheus-prometheus 9090:9090 &
sleep 3

curl "http://localhost:9090/api/v1/query?query=trisla_network_latency_ms"
curl "http://localhost:9090/api/v1/query?query=trisla_network_throughput_mbps"
curl "http://localhost:9090/api/v1/query?query=trisla_network_packet_loss_ratio"

FASE 6 — CONFIRMAR USO DAS MÉTRICAS PELO ML
kubectl logs deploy/trisla-ml-nsmf -n $NS | grep real_metrics


Esperado:

real_metrics_count >= 3

FASE 7 — SUBMISSÃO DE SLA (ACCEPT REAL)
kubectl -n $NS port-forward svc/trisla-portal-backend 8080:80 &
sleep 2

curl -X POST http://localhost:8080/api/v1/sla \
  -H "Content-Type: application/json" \
  -d @sla_accept_profile.json | tee $WORKDIR/sla_accept.json


Esperado:

decision = ACCEPT

FASE 8 — VALIDAÇÕES FINAIS (CADEIA COMPLETA)
Kafka
kubectl exec -n $NS deploy/kafka -- \
  kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic trisla-decision-events \
  --from-beginning | tee $WORKDIR/kafka_events.txt

XAI
curl http://localhost:8080/api/v1/explain \
  -d @sla_accept.json | tee $WORKDIR/xai_accept.json

Blockchain
kubectl logs deploy/trisla-bc-nssmf -n $NS | tee $WORKDIR/bc_logs.txt

FASE 9 — MÉTRICAS DE RECURSOS E E2E
kubectl top pods -n $NS > $WORKDIR/top_pods.txt
kubectl top nodes > $WORKDIR/top_nodes.txt
df -h > $WORKDIR/disk_usage.txt

FASE 10 — FREEZE FINAL
sha256sum $WORKDIR/* > $WORKDIR/CHECKSUMS.sha256

RESULTADO ESPERADO (OBJETIVO FINAL)

✔ ACCEPT real
✔ Métricas reais de tráfego
✔ XAI para ACCEPT / RENEG / REJECT
✔ Evento Kafka
✔ Transação Blockchain
✔ Latência E2E mensurável
✔ Sistema fechado de ponta a ponta