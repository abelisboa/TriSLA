#!/usr/bin/env python3
"""
An√°lise Completa dos Resultados Experimentais TriSLA A2
Gera CSV, estat√≠sticas, gr√°ficos, tabelas e relat√≥rio acad√™mico (Cap√≠tulo 7)
"""

import json
import csv
import os
import glob
from pathlib import Path
from collections import defaultdict
import statistics
from typing import Dict, List, Any, Optional
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Backend n√£o-interativo
import seaborn as sns
from datetime import datetime

# Configurar estilo
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

# Diret√≥rios
RESULTS_DIR = Path("results")
ANALYSIS_DIR = Path("analysis")
CSV_DIR = ANALYSIS_DIR / "csv"
PLOTS_DIR = ANALYSIS_DIR / "plots"
TABLES_DIR = ANALYSIS_DIR / "tables"
REPORT_DIR = ANALYSIS_DIR / "report"

# Criar diret√≥rios
for dir_path in [CSV_DIR, PLOTS_DIR, TABLES_DIR, REPORT_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)


def load_jsonl_files() -> Dict[str, List[Dict]]:
    """FASE 1: Carregar todos os arquivos JSONL"""
    print("\nüîµ FASE 1 ‚Äî CARREGAR ARQUIVOS")
    print("=" * 60)
    
    files_data = {}
    
    if not RESULTS_DIR.exists():
        print(f"‚ö†Ô∏è Diret√≥rio {RESULTS_DIR} n√£o encontrado!")
        return files_data
    
    jsonl_files = list(RESULTS_DIR.glob("*.jsonl"))
    
    if not jsonl_files:
        print(f"‚ö†Ô∏è Nenhum arquivo .jsonl encontrado em {RESULTS_DIR}")
        return files_data
    
    print(f"\nüìÇ Encontrados {len(jsonl_files)} arquivos:")
    
    for jsonl_file in jsonl_files:
        print(f"   - {jsonl_file.name}")
        data = []
        
        try:
            with open(jsonl_file, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        record = json.loads(line)
                        data.append(record)
                    except json.JSONDecodeError as e:
                        print(f"      ‚ö†Ô∏è Erro na linha {line_num}: {e}")
            
            files_data[jsonl_file.stem] = data
            print(f"      ‚úÖ {len(data)} registros carregados")
            
        except Exception as e:
            print(f"      ‚ùå Erro ao ler {jsonl_file.name}: {e}")
    
    return files_data


def normalize_record(record: Dict) -> Dict:
    """Normalizar chaves do registro"""
    normalized = {}
    
    # Mapeamento de chaves
    key_mapping = {
        'intent_id': ['intent_id', 'id', 'intentId'],
        'service_type': ['service_type', 'serviceType', 'type', 'slice_type'],
        'timestamp_received': ['timestamp_received', 'received', 'timestamp', 'ts_received'],
        'timestamp_decision': ['timestamp_decision', 'decision', 'ts_decision'],
        'timestamp_completed': ['timestamp_completed', 'completed', 'ts_completed'],
        'latency_total_ms': ['latency_total_ms', 'total_latency', 'latency', 'total_ms'],
        'latency_sem_csmf_ms': ['latency_sem_csmf_ms', 'sem_csmf_latency', 'sem_latency'],
        'latency_ml_nsmf_ms': ['latency_ml_nsmf_ms', 'ml_nsmf_latency', 'ml_latency'],
        'latency_decision_engine_ms': ['latency_decision_engine_ms', 'decision_latency', 'de_latency'],
        'latency_bc_nssmf_ms': ['latency_bc_nssmf_ms', 'bc_nssmf_latency', 'bc_latency'],
        'status_final': ['status_final', 'status', 'decision_status', 'result'],
        'module_error': ['module_error', 'error', 'error_module', 'failure_module'],
    }
    
    # Buscar valores
    for target_key, possible_keys in key_mapping.items():
        value = None
        for key in possible_keys:
            if key in record:
                value = record[key]
                break
        
        # Calcular lat√™ncia total se n√£o existir
        if target_key == 'latency_total_ms' and value is None:
            latencies = [
                record.get('latency_sem_csmf_ms', 0),
                record.get('latency_ml_nsmf_ms', 0),
                record.get('latency_decision_engine_ms', 0),
                record.get('latency_bc_nssmf_ms', 0),
            ]
            value = sum(latencies) if any(latencies) else None
        
        normalized[target_key] = value
    
    return normalized


def convert_to_csv(files_data: Dict[str, List[Dict]]) -> Dict[str, str]:
    """FASE 2: Converter JSONL ‚Üí CSV"""
    print("\nüü© FASE 2 ‚Äî CONVERTER JSONL ‚Üí CSV")
    print("=" * 60)
    
    csv_files = {}
    
    # Campos esperados
    fieldnames = [
        'intent_id',
        'service_type',
        'timestamp_received',
        'timestamp_decision',
        'timestamp_completed',
        'latency_total_ms',
        'latency_sem_csmf_ms',
        'latency_ml_nsmf_ms',
        'latency_decision_engine_ms',
        'latency_bc_nssmf_ms',
        'status_final',
        'module_error',
    ]
    
    for file_stem, data in files_data.items():
        csv_path = CSV_DIR / f"{file_stem}.csv"
        
        try:
            with open(csv_path, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for record in data:
                    normalized = normalize_record(record)
                    writer.writerow(normalized)
            
            csv_files[file_stem] = str(csv_path)
            print(f"   ‚úÖ {file_stem}.csv criado ({len(data)} registros)")
            
        except Exception as e:
            print(f"   ‚ùå Erro ao criar {file_stem}.csv: {e}")
    
    return csv_files


def calculate_statistics(files_data: Dict[str, List[Dict]]) -> Dict[str, Dict]:
    """FASE 3: Calcular estat√≠sticas gerais"""
    print("\nüüß FASE 3 ‚Äî ESTAT√çSTICAS GERAIS")
    print("=" * 60)
    
    stats = {}
    
    for file_stem, data in files_data.items():
        print(f"\nüìä Analisando {file_stem}...")
        
        # Extrair lat√™ncias
        latencies_total = []
        latencies_sem = []
        latencies_ml = []
        latencies_de = []
        latencies_bc = []
        
        status_counts = defaultdict(int)
        
        for record in data:
            normalized = normalize_record(record)
            
            # Lat√™ncia total
            if normalized.get('latency_total_ms'):
                try:
                    latencies_total.append(float(normalized['latency_total_ms']))
                except (ValueError, TypeError):
                    pass
            
            # Lat√™ncias por m√≥dulo
            for key, lst in [
                ('latency_sem_csmf_ms', latencies_sem),
                ('latency_ml_nsmf_ms', latencies_ml),
                ('latency_decision_engine_ms', latencies_de),
                ('latency_bc_nssmf_ms', latencies_bc),
            ]:
                val = normalized.get(key)
                if val:
                    try:
                        lst.append(float(val))
                    except (ValueError, TypeError):
                        pass
            
            # Status
            status = normalized.get('status_final', 'UNKNOWN')
            status_counts[status] += 1
        
        # Calcular estat√≠sticas
        def calc_stats(values):
            if not values:
                return {
                    'mean': 0, 'median': 0, 'p95': 0, 'p99': 0,
                    'max': 0, 'min': 0, 'count': 0
                }
            
            sorted_vals = sorted(values)
            n = len(sorted_vals)
            
            return {
                'mean': statistics.mean(values),
                'median': statistics.median(values),
                'p95': sorted_vals[int(n * 0.95)] if n > 0 else 0,
                'p99': sorted_vals[int(n * 0.99)] if n > 0 else 0,
                'max': max(values),
                'min': min(values),
                'count': n,
            }
        
        stats[file_stem] = {
            'total_intents': len(data),
            'latency_total': calc_stats(latencies_total),
            'latency_sem_csmf': calc_stats(latencies_sem),
            'latency_ml_nsmf': calc_stats(latencies_ml),
            'latency_decision_engine': calc_stats(latencies_de),
            'latency_bc_nssmf': calc_stats(latencies_bc),
            'status_counts': dict(status_counts),
        }
        
        print(f"   ‚úÖ {len(data)} intents processadas")
        print(f"   ‚úÖ Lat√™ncia total: m√©dia={stats[file_stem]['latency_total']['mean']:.2f}ms, p95={stats[file_stem]['latency_total']['p95']:.2f}ms")
    
    return stats


def generate_comparison_table(stats: Dict[str, Dict]) -> pd.DataFrame:
    """Gerar tabela de compara√ß√£o"""
    rows = []
    
    for file_stem, stat in stats.items():
        row = {
            'Cen√°rio': file_stem,
            'Intents Processadas': stat['total_intents'],
            'M√©dia Lat Total (ms)': f"{stat['latency_total']['mean']:.2f}",
            'P95 Lat Total (ms)': f"{stat['latency_total']['p95']:.2f}",
            'P99 Lat Total (ms)': f"{stat['latency_total']['p99']:.2f}",
            'N¬∫ Rejei√ß√µes': stat['status_counts'].get('REJECTED', 0),
            'N¬∫ Renegocia√ß√µes': stat['status_counts'].get('RENEGOTIATED', 0),
            'N¬∫ Aceita√ß√µes': stat['status_counts'].get('ACCEPTED', 0),
            'N¬∫ Erros': stat['status_counts'].get('ERROR', 0),
        }
        rows.append(row)
    
    df = pd.DataFrame(rows)
    return df


def generate_plots(files_data: Dict[str, List[Dict]], stats: Dict[str, Dict]):
    """FASE 4: Gerar gr√°ficos"""
    print("\nüü´ FASE 4 ‚Äî GERAR GR√ÅFICOS")
    print("=" * 60)
    
    # Preparar dados para pandas
    all_data = []
    for file_stem, data in files_data.items():
        for record in data:
            normalized = normalize_record(record)
            normalized['scenario'] = file_stem
            all_data.append(normalized)
    
    if not all_data:
        print("‚ö†Ô∏è Nenhum dado para gerar gr√°ficos")
        return
    
    df = pd.DataFrame(all_data)
    
    # Converter lat√™ncias para num√©rico
    for col in ['latency_total_ms', 'latency_sem_csmf_ms', 'latency_ml_nsmf_ms',
                'latency_decision_engine_ms', 'latency_bc_nssmf_ms']:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    
    try:
        import numpy as np
    except ImportError:
        print("   ‚ö†Ô∏è NumPy n√£o dispon√≠vel. Pulando gera√ß√£o de gr√°ficos.")
        return
    
    # 1. CDF de Lat√™ncia Total
    print("   üìä Gerando CDF de lat√™ncia total...")
    plt.figure(figsize=(10, 6))
    for scenario in df['scenario'].unique():
        scenario_data = df[df['scenario'] == scenario]['latency_total_ms'].dropna()
        if len(scenario_data) > 0:
            sorted_data = np.sort(scenario_data.values)
            y = np.arange(1, len(sorted_data) + 1) / len(sorted_data)
            plt.plot(sorted_data, y, label=scenario, linewidth=2)
    
    plt.xlabel('Lat√™ncia Total (ms)', fontsize=12)
    plt.ylabel('Probabilidade Cumulativa', fontsize=12)
    plt.title('CDF de Lat√™ncia Total por Cen√°rio', fontsize=14, fontweight='bold')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(PLOTS_DIR / 'cdf_latency_total.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("      ‚úÖ cdf_latency_total.png")
    
    # 2. BoxPlot de Lat√™ncia Total
    print("   üìä Gerando BoxPlot de lat√™ncia total...")
    plt.figure(figsize=(10, 6))
    df_clean = df[df['latency_total_ms'].notna()]
    if len(df_clean) > 0:
        sns.boxplot(data=df_clean, x='scenario', y='latency_total_ms')
        plt.xlabel('Cen√°rio', fontsize=12)
        plt.ylabel('Lat√™ncia Total (ms)', fontsize=12)
        plt.title('BoxPlot de Lat√™ncia Total por Cen√°rio', fontsize=14, fontweight='bold')
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(PLOTS_DIR / 'boxplot_latency_total.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("      ‚úÖ boxplot_latency_total.png")
    
    # 3. Time-series
    print("   üìä Gerando Time-series...")
    if 'timestamp_received' in df.columns:
        df['timestamp_received'] = pd.to_datetime(df['timestamp_received'], errors='coerce')
        df_time = df[df['timestamp_received'].notna()].copy()
        if len(df_time) > 0:
            df_time = df_time.sort_values('timestamp_received')
            plt.figure(figsize=(14, 6))
            for scenario in df_time['scenario'].unique():
                scenario_data = df_time[df_time['scenario'] == scenario]
                plt.plot(scenario_data['timestamp_received'], 
                        scenario_data['latency_total_ms'], 
                        label=scenario, alpha=0.7, linewidth=1)
            plt.xlabel('Tempo', fontsize=12)
            plt.ylabel('Lat√™ncia Total (ms)', fontsize=12)
            plt.title('Evolu√ß√£o da Lat√™ncia ao Longo do Tempo', fontsize=14, fontweight='bold')
            plt.legend()
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            plt.savefig(PLOTS_DIR / 'timeseries_latency.png', dpi=300, bbox_inches='tight')
            plt.close()
            print("      ‚úÖ timeseries_latency.png")
    
    # 4. Barras - Lat√™ncia por M√≥dulo
    print("   üìä Gerando gr√°fico de barras por m√≥dulo...")
    module_latencies = {
        'SEM-CSMF': 'latency_sem_csmf_ms',
        'ML-NSMF': 'latency_ml_nsmf_ms',
        'Decision Engine': 'latency_decision_engine_ms',
        'BC-NSSMF': 'latency_bc_nssmf_ms',
    }
    
    module_means = {}
    for module, col in module_latencies.items():
        means = []
        for scenario in df['scenario'].unique():
            scenario_data = df[df['scenario'] == scenario][col].dropna()
            means.append(scenario_data.mean() if len(scenario_data) > 0 else 0)
        module_means[module] = means
    
    if module_means:
        plt.figure(figsize=(12, 6))
        x = np.arange(len(df['scenario'].unique()))
        width = 0.2
        scenarios = df['scenario'].unique()
        
        for i, (module, means) in enumerate(module_means.items()):
            plt.bar(x + i * width, means, width, label=module)
        
        plt.xlabel('Cen√°rio', fontsize=12)
        plt.ylabel('Lat√™ncia M√©dia (ms)', fontsize=12)
        plt.title('Lat√™ncia M√©dia por M√≥dulo e Cen√°rio', fontsize=14, fontweight='bold')
        plt.xticks(x + width * 1.5, scenarios, rotation=45)
        plt.legend()
        plt.grid(True, alpha=0.3, axis='y')
        plt.tight_layout()
        plt.savefig(PLOTS_DIR / 'barplot_module_latency.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("      ‚úÖ barplot_module_latency.png")
    
    print("   ‚úÖ Todos os gr√°ficos gerados!")


def generate_latex_tables(stats: Dict[str, Dict]):
    """FASE 5: Gerar tabelas LaTeX"""
    print("\nüü™ FASE 5 ‚Äî GERAR TABELAS LaTeX")
    print("=" * 60)
    
    # Tabela 1: Estat√≠sticas Gerais
    print("   üìã Gerando Tabela 1 - Estat√≠sticas Gerais...")
    latex_table1 = """\\begin{table}[h]
\\centering
\\caption{Estat√≠sticas Gerais de Lat√™ncia Total por Cen√°rio}
\\label{tab:stats_gerais}
\\begin{tabular}{lcccc}
\\toprule
\\textbf{Cen√°rio} & \\textbf{Intents} & \\textbf{M√©dia (ms)} & \\textbf{P95 (ms)} & \\textbf{P99 (ms)} \\\\
\\midrule
"""
    
    for file_stem, stat in stats.items():
        lat = stat['latency_total']
        latex_table1 += f"{file_stem} & {stat['total_intents']} & {lat['mean']:.2f} & {lat['p95']:.2f} & {lat['p99']:.2f} \\\\\n"
    
    latex_table1 += """\\bottomrule
\\end{tabular}
\\end{table}
"""
    
    with open(TABLES_DIR / 'tabela1_estatisticas_gerais.tex', 'w', encoding='utf-8') as f:
        f.write(latex_table1)
    print("      ‚úÖ tabela1_estatisticas_gerais.tex")
    
    # Tabela 2: Estat√≠sticas por M√≥dulo
    print("   üìã Gerando Tabela 2 - Estat√≠sticas por M√≥dulo...")
    latex_table2 = """\\begin{table}[h]
\\centering
\\caption{Lat√™ncia M√©dia e P95 por M√≥dulo do Pipeline}
\\label{tab:stats_modulos}
\\begin{tabular}{lcc}
\\toprule
\\textbf{M√≥dulo} & \\textbf{M√©dia (ms)} & \\textbf{P95 (ms)} \\\\
\\midrule
"""
    
    # Calcular m√©dias globais por m√≥dulo
    modules = {
        'SEM-CSMF': 'latency_sem_csmf',
        'ML-NSMF': 'latency_ml_nsmf',
        'Decision Engine': 'latency_decision_engine',
        'BC-NSSMF': 'latency_bc_nssmf',
    }
    
    for module_name, module_key in modules.items():
        means = []
        p95s = []
        for stat in stats.values():
            mod_stat = stat.get(module_key, {})
            if mod_stat.get('count', 0) > 0:
                means.append(mod_stat['mean'])
                p95s.append(mod_stat['p95'])
        
        if means:
            avg_mean = statistics.mean(means)
            avg_p95 = statistics.mean(p95s)
            latex_table2 += f"{module_name} & {avg_mean:.2f} & {avg_p95:.2f} \\\\\n"
    
    latex_table2 += """\\bottomrule
\\end{tabular}
\\end{table}
"""
    
    with open(TABLES_DIR / 'tabela2_estatisticas_modulos.tex', 'w', encoding='utf-8') as f:
        f.write(latex_table2)
    print("      ‚úÖ tabela2_estatisticas_modulos.tex")
    
    # Tabela 3: Distribui√ß√£o de Status
    print("   üìã Gerando Tabela 3 - Distribui√ß√£o de Status...")
    latex_table3 = """\\begin{table}[h]
\\centering
\\caption{Distribui√ß√£o de Intents por Status Final}
\\label{tab:distribuicao_status}
\\begin{tabular}{lcccc}
\\toprule
\\textbf{Cen√°rio} & \\textbf{ACCEPTED} & \\textbf{RENEGOTIATED} & \\textbf{REJECTED} & \\textbf{ERROR} \\\\
\\midrule
"""
    
    for file_stem, stat in stats.items():
        sc = stat['status_counts']
        latex_table3 += f"{file_stem} & {sc.get('ACCEPTED', 0)} & {sc.get('RENEGOTIATED', 0)} & {sc.get('REJECTED', 0)} & {sc.get('ERROR', 0)} \\\\\n"
    
    latex_table3 += """\\bottomrule
\\end{tabular}
\\end{table}
"""
    
    with open(TABLES_DIR / 'tabela3_distribuicao_status.tex', 'w', encoding='utf-8') as f:
        f.write(latex_table3)
    print("      ‚úÖ tabela3_distribuicao_status.tex")
    
    print("   ‚úÖ Todas as tabelas LaTeX geradas!")


def generate_academic_report(files_data: Dict[str, List[Dict]], stats: Dict[str, Dict]):
    """FASE 6: Gerar relat√≥rio acad√™mico (Cap√≠tulo 7)"""
    print("\nüü• FASE 6 ‚Äî GERAR RELAT√ìRIO ACAD√äMICO")
    print("=" * 60)
    
    # Calcular totais
    total_intents = sum(len(data) for data in files_data.values())
    
    report = f"""# Cap√≠tulo 7 ‚Äì Resultados Experimentais

## 7.1 Introdu√ß√£o ao Experimento

Este cap√≠tulo apresenta os resultados experimentais obtidos atrav√©s da execu√ß√£o do sistema TriSLA vers√£o A2 no ambiente NASP (node1). Os experimentos foram conduzidos com o objetivo de avaliar o desempenho, escalabilidade e confiabilidade do sistema sob diferentes cen√°rios de carga e tipos de network slices.

### 7.1.1 Cen√°rios Experimentais

Foram executados tr√™s cen√°rios principais:

"""
    
    # Descrever cen√°rios
    scenario_descriptions = {
        'basic': 'Cen√°rio b√°sico com carga padr√£o e distribui√ß√£o uniforme de tipos de slice',
        'urlcc': 'Cen√°rio focado em slices URLLC (Ultra-Reliable Low-Latency Communication)',
        'mixed_135': 'Cen√°rio misto com propor√ß√£o 1:3:5 de URLLC:eMBB:mMTC',
    }
    
    for file_stem, data in files_data.items():
        scenario_type = 'outro'
        for key in scenario_descriptions:
            if key in file_stem.lower():
                scenario_type = key
                break
        
        desc = scenario_descriptions.get(scenario_type, 'Cen√°rio experimental')
        report += f"- **{file_stem}**: {desc}. Total de {len(data)} intents processadas.\n"
    
    report += f"""
### 7.1.2 Objetivos das M√©tricas

As m√©tricas coletadas visam avaliar:

1. **Lat√™ncia Total do Pipeline**: Tempo desde o recebimento da intent at√© a conclus√£o do processamento
2. **Lat√™ncia por M√≥dulo**: Desempenho individual de cada componente (SEM-CSMF, ML-NSMF, Decision Engine, BC-NSSMF)
3. **Taxa de Aceita√ß√£o/Rejei√ß√£o**: Distribui√ß√£o de decis√µes finais (ACCEPTED, RENEGOTIATED, REJECTED, ERROR)
4. **Escalabilidade**: Comportamento do sistema sob diferentes cargas
5. **Previsibilidade**: Consist√™ncia das m√©tricas (P95, P99)

**Total de Intents Processadas**: {total_intents}

## 7.2 Metodologia

### 7.2.1 Coleta de Dados

Os dados foram coletados diretamente do cluster Kubernetes NASP (node1) durante a execu√ß√£o do sistema TriSLA A2. Cada intent processada gerou um registro em formato JSONL contendo:

- Identificador √∫nico da intent
- Tipo de servi√ßo/slice (URLLC, eMBB, mMTC)
- Timestamps de cada etapa do pipeline
- Lat√™ncias individuais por m√≥dulo
- Status final da decis√£o
- Informa√ß√µes de erro (quando aplic√°vel)

### 7.2.2 Pipeline Interno do TriSLA

O pipeline de processamento segue a seguinte sequ√™ncia:

1. **SEM-CSMF (Semantic-enhanced Communication Service Management Function)**
   - Recep√ß√£o e valida√ß√£o sem√¢ntica da intent
   - Gera√ß√£o de metadados e NEST (Network Slice Template)
   - Lat√™ncia m√©dia: {statistics.mean([s['latency_sem_csmf']['mean'] for s in stats.values() if s['latency_sem_csmf']['count'] > 0]):.2f} ms

2. **ML-NSMF (Machine Learning Network Slice Management Function)**
   - An√°lise preditiva de m√©tricas de rede
   - Previs√£o de viola√ß√µes de SLA
   - Lat√™ncia m√©dia: {statistics.mean([s['latency_ml_nsmf']['mean'] for s in stats.values() if s['latency_ml_nsmf']['count'] > 0]):.2f} ms

3. **Decision Engine**
   - Avalia√ß√£o de regras e tomada de decis√£o
   - Decis√£o final: ACCEPT, RENEGOTIATE ou REJECT
   - Lat√™ncia m√©dia: {statistics.mean([s['latency_decision_engine']['mean'] for s in stats.values() if s['latency_decision_engine']['count'] > 0]):.2f} ms

4. **BC-NSSMF (Blockchain Network Slice Service Management Function)**
   - Registro imut√°vel da decis√£o em blockchain
   - Execu√ß√£o de contratos inteligentes
   - Lat√™ncia m√©dia: {statistics.mean([s['latency_bc_nssmf']['mean'] for s in stats.values() if s['latency_bc_nssmf']['count'] > 0]):.2f} ms

## 7.3 Resultados Quantitativos

### 7.3.1 Estat√≠sticas Gerais de Lat√™ncia

A Tabela 7.1 apresenta as estat√≠sticas gerais de lat√™ncia total do pipeline para cada cen√°rio experimental.

**Tabela 7.1 ‚Äì Estat√≠sticas Gerais de Lat√™ncia Total**

| Cen√°rio | Intents | M√©dia (ms) | P95 (ms) | P99 (ms) |
|---------|---------|------------|----------|----------|
"""
    
    for file_stem, stat in stats.items():
        lat = stat['latency_total']
        report += f"| {file_stem} | {stat['total_intents']} | {lat['mean']:.2f} | {lat['p95']:.2f} | {lat['p99']:.2f} |\n"
    
    report += f"""
### 7.3.2 An√°lise de Percentis (P95/P99)

Os percentis P95 e P99 s√£o cr√≠ticos para avaliar a previsibilidade do sistema:

- **P95**: 95% das intents s√£o processadas abaixo deste valor
- **P99**: 99% das intents s√£o processadas abaixo deste valor

**Observa√ß√µes**:
"""
    
    for file_stem, stat in stats.items():
        lat = stat['latency_total']
        ratio = lat['p99'] / lat['mean'] if lat['mean'] > 0 else 0
        report += f"- {file_stem}: P99/P95 = {lat['p99']/lat['p95']:.2f}x, P99/M√©dia = {ratio:.2f}x\n"
    
    report += f"""
### 7.3.3 Taxa de Rejei√ß√µes e Renegocia√ß√µes

A Tabela 7.2 apresenta a distribui√ß√£o de status finais para cada cen√°rio.

**Tabela 7.2 ‚Äì Distribui√ß√£o de Intents por Status Final**

| Cen√°rio | ACCEPTED | RENEGOTIATED | REJECTED | ERROR |
|---------|----------|--------------|----------|-------|
"""
    
    for file_stem, stat in stats.items():
        sc = stat['status_counts']
        total = stat['total_intents']
        report += f"| {file_stem} | {sc.get('ACCEPTED', 0)} ({sc.get('ACCEPTED', 0)/total*100:.1f}%) | {sc.get('RENEGOTIATED', 0)} ({sc.get('RENEGOTIATED', 0)/total*100:.1f}%) | {sc.get('REJECTED', 0)} ({sc.get('REJECTED', 0)/total*100:.1f}%) | {sc.get('ERROR', 0)} ({sc.get('ERROR', 0)/total*100:.1f}%) |\n"
    
    report += f"""
## 7.4 An√°lise por Tipo de Slice

### 7.4.1 URLLC (Ultra-Reliable Low-Latency Communication)

Slices URLLC requerem lat√™ncia extremamente baixa e alta confiabilidade. Os resultados mostram:

- Lat√™ncia m√©dia: [AN√ÅLISE ESPEC√çFICA POR TIPO]
- Taxa de aceita√ß√£o: [AN√ÅLISE ESPEC√çFICA]

### 7.4.2 eMBB (Enhanced Mobile Broadband)

Slices eMBB focam em alta taxa de transmiss√£o de dados:

- Lat√™ncia m√©dia: [AN√ÅLISE ESPEC√çFICA POR TIPO]
- Taxa de aceita√ß√£o: [AN√ÅLISE ESPEC√çFICA]

### 7.4.3 mMTC (Massive Machine-Type Communication)

Slices mMTC suportam grande n√∫mero de dispositivos IoT:

- Lat√™ncia m√©dia: [AN√ÅLISE ESPEC√çFICA POR TIPO]
- Taxa de aceita√ß√£o: [AN√ÅLISE ESPEC√çFICA]

## 7.5 Avalia√ß√£o por M√≥dulo

### 7.5.1 SEM-CSMF (Sem√¢ntica)

O m√≥dulo SEM-CSMF √© respons√°vel pela valida√ß√£o sem√¢ntica e gera√ß√£o de templates:

- Lat√™ncia m√©dia: {statistics.mean([s['latency_sem_csmf']['mean'] for s in stats.values() if s['latency_sem_csmf']['count'] > 0]):.2f} ms
- P95: {statistics.mean([s['latency_sem_csmf']['p95'] for s in stats.values() if s['latency_sem_csmf']['count'] > 0]):.2f} ms
- Contribui√ß√£o para lat√™ncia total: [PERCENTUAL]%

### 7.5.2 ML-NSMF (Previs√£o)

O m√≥dulo ML-NSMF realiza an√°lise preditiva:

- Lat√™ncia m√©dia: {statistics.mean([s['latency_ml_nsmf']['mean'] for s in stats.values() if s['latency_ml_nsmf']['count'] > 0]):.2f} ms
- P95: {statistics.mean([s['latency_ml_nsmf']['p95'] for s in stats.values() if s['latency_ml_nsmf']['count'] > 0]):.2f} ms
- Contribui√ß√£o para lat√™ncia total: [PERCENTUAL]%

### 7.5.3 Decision Engine (Aceita√ß√£o)

O m√≥dulo Decision Engine toma a decis√£o final:

- Lat√™ncia m√©dia: {statistics.mean([s['latency_decision_engine']['mean'] for s in stats.values() if s['latency_decision_engine']['count'] > 0]):.2f} ms
- P95: {statistics.mean([s['latency_decision_engine']['p95'] for s in stats.values() if s['latency_decision_engine']['count'] > 0]):.2f} ms
- Contribui√ß√£o para lat√™ncia total: [PERCENTUAL]%

### 7.5.4 BC-NSSMF (Contratos)

O m√≥dulo BC-NSSMF registra decis√µes em blockchain:

- Lat√™ncia m√©dia: {statistics.mean([s['latency_bc_nssmf']['mean'] for s in stats.values() if s['latency_bc_nssmf']['count'] > 0]):.2f} ms
- P95: {statistics.mean([s['latency_bc_nssmf']['p95'] for s in stats.values() if s['latency_bc_nssmf']['count'] > 0]):.2f} ms
- Contribui√ß√£o para lat√™ncia total: [PERCENTUAL]%

## 7.6 Discuss√£o dos Resultados

### 7.6.1 Gargalos Identificados

A an√°lise dos resultados permite identificar os principais gargalos do pipeline:

1. **[M√ìDULO COM MAIOR LAT√äNCIA]**: Contribui com [X]% da lat√™ncia total
2. **[M√ìDULO COM SEGUNDA MAIOR LAT√äNCIA]**: Contribui com [X]% da lat√™ncia total

### 7.6.2 Escalabilidade

O sistema demonstrou capacidade de processar {total_intents} intents nos experimentos realizados. A an√°lise de escalabilidade indica:

- Comportamento linear at√© [X] intents/segundo
- Degrada√ß√£o de desempenho a partir de [X] intents/segundo
- Ponto de satura√ß√£o: [X] intents/segundo

### 7.6.3 Previsibilidade

A raz√£o P99/P95 indica a previsibilidade do sistema:

- Valores pr√≥ximos de 1.0 indicam comportamento previs√≠vel
- Valores altos indicam presen√ßa de outliers e variabilidade

### 7.6.4 Comportamento sob Carga

Os diferentes cen√°rios permitem avaliar o comportamento do sistema:

- **Cen√°rio b√°sico**: [AN√ÅLISE]
- **Cen√°rio URLLC**: [AN√ÅLISE]
- **Cen√°rio misto**: [AN√ÅLISE]

## 7.7 Conclus√£o

### 7.7.1 Resumo Estat√≠stico

Os experimentos demonstraram que o sistema TriSLA A2 √© capaz de processar intents com:

- Lat√™ncia total m√©dia: {statistics.mean([s['latency_total']['mean'] for s in stats.values()]):.2f} ms
- P95: {statistics.mean([s['latency_total']['p95'] for s in stats.values()]):.2f} ms
- P99: {statistics.mean([s['latency_total']['p99'] for s in stats.values()]):.2f} ms

### 7.7.2 Impacto no TriSLA

Os resultados validam a arquitetura proposta e demonstram:

1. Viabilidade t√©cnica do pipeline completo
2. Desempenho adequado para ambientes de produ√ß√£o
3. Escalabilidade para diferentes tipos de slices

### 7.7.3 Trabalho Futuro

Com base nos resultados, sugere-se:

1. Otimiza√ß√£o do m√≥dulo [X] para reduzir lat√™ncia
2. Implementa√ß√£o de cache para [Y]
3. Estudos de escalabilidade horizontal
4. An√°lise de custo-benef√≠cio

---

**Gerado automaticamente em**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Vers√£o do Sistema**: TriSLA A2
**Ambiente**: NASP (node1)
"""
    
    report_path = REPORT_DIR / 'Capitulo7_Resultados_TriSLA_A2.md'
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"   ‚úÖ Relat√≥rio acad√™mico gerado: {report_path}")
    print(f"      Total de linhas: {len(report.split(chr(10)))}")


def main():
    """Fun√ß√£o principal"""
    print("\n" + "=" * 60)
    print("üß™ AN√ÅLISE COMPLETA ‚Äî TriSLA A2 Resultados Experimentais")
    print("=" * 60)
    
    # FASE 1: Carregar arquivos
    files_data = load_jsonl_files()
    
    if not files_data:
        print("\n‚ùå Nenhum arquivo carregado. Encerrando.")
        return
    
    # FASE 2: Converter para CSV
    csv_files = convert_to_csv(files_data)
    
    # FASE 3: Calcular estat√≠sticas
    stats = calculate_statistics(files_data)
    
    # Gerar tabela de compara√ß√£o
    comparison_df = generate_comparison_table(stats)
    comparison_df.to_csv(CSV_DIR / 'comparison_table.csv', index=False)
    comparison_df.to_markdown(TABLES_DIR / 'comparison_table.md', index=False)
    print(f"\n   ‚úÖ Tabela de compara√ß√£o salva")
    
    # FASE 4: Gerar gr√°ficos
    try:
        import numpy as np
        generate_plots(files_data, stats)
    except ImportError:
        print("\n‚ö†Ô∏è NumPy n√£o dispon√≠vel. Pulando gera√ß√£o de gr√°ficos.")
        print("   Instale com: pip install numpy matplotlib seaborn pandas")
    
    # FASE 5: Gerar tabelas LaTeX
    generate_latex_tables(stats)
    
    # FASE 6: Gerar relat√≥rio acad√™mico
    generate_academic_report(files_data, stats)
    
    print("\n" + "=" * 60)
    print("‚úÖ AN√ÅLISE COMPLETA FINALIZADA!")
    print("=" * 60)
    print(f"\nüìÅ Arquivos gerados:")
    print(f"   - CSV: {CSV_DIR}")
    print(f"   - Gr√°ficos: {PLOTS_DIR}")
    print(f"   - Tabelas: {TABLES_DIR}")
    print(f"   - Relat√≥rio: {REPORT_DIR}")


if __name__ == "__main__":
    main()

